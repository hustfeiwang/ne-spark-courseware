
<html>
  <head>
    <title>RDD概述</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        ffont-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 2em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #fff;
        line-height: 0.8em;
      }
    
      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }
    
      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column h2:last-of-type, .left-column h3:last-of-type {
        color: #000;
      }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
    
      /* Two-column layout inverse*/
      .left-column-inverse {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .left-column-inverse h2:last-of-type, .left-column-inverse h3:last-of-type {
        color: #fff;
      }
      .right-column-inverse {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
      .right-column-inverse h2, .right-column-inverse h3, .right-column-inverse h4 {
        color: #fff;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle, inverse

## [NetEase Spark Courses](https://netease-bigdata.github.io/ne-spark-courseware/)

<br>
<br>
<br>
<br>

## Spark RDD 概述

<br>
<br>
<br>
<br>

<img style="zoom: 1.0" src="../../imgs/mammut.png"  align="bottom" />

???
备注：标题 <br>
帮助信息：在网页端按H键可进入帮助页面

---

class:  center,inverse
name: rdd

  # Agenda
  ## -
  ** About Me **<br>
  ## -
  **  RDD定义及特点  **<br>
  ** RDD Operations **<br>
  ** RDD 依赖 **<br>
  ** RDD Persist **<br>
  ** 相关链接 **<br>

---
class: 
name:
.left-column[
## About Me
]
.right-column[
## 王斐

2018年校招加入网易，硕士期间研究Spark平台内存优化，目前在杭州研究院-数据科学中心负责Spark平台开发相关工作。
]
---


class:
name:

.left-column[
### RDD定义及特点
#### RDD定义

]
.right-column[
RDD(Resilient Distributed Datasets),弹性分布式数据集，是对分布式内存的抽象。
<figure class="half">
    <img src="../../imgs/rdd_basics/rdd-inmemory.png" width="45%" height="40%">
    <img src="../../imgs/rdd_basics/rdd-itr.png" width="45%"  height="40%">
</figure>
]

---
class:
name:
.left-column[
### RDD定义及特点
#### RDD定义
#### RDD特点

]
.right-column[
#### 只读，不可变
#### 分区
#### 血缘
#### 延迟计算
<figure class="half">
    <img src="../../imgs/rdd_basics/rdd-feature.png" width="100%"  height="35%">
</figure>

]



---
class:
name:
.left-column[
## RDD Operations
<!-- ### transformation & action
 -->
 ### transformation
]
.right-column[
transformation：从数据源生成RDD或者对已存在的RDD进行转换生成新RDD。

  | transformation | Meaning |
| -- | :-----: |
|  textFile/objectFile| 从数据源生成RDD|
| map(func)      | 对每条record进行函数计算 |
| filter(func) | 过滤掉符合条件的records |
| flatMap(func) | 将records的按照规则进行展开 |
| mapPartitions(func) | 以RDD的每个分区进行函数计算 |
| mapPartitionsWithIndex(func) |   对分区操作，提供partitionId参数      |
| sample(withReplacement, fraction, seed) | 返回一个子集 |
| intersection(otherDataset) | 返回两个RDD的交集        |
| distinct([numPartitions])) |   返回一个不包含重复record的数据集      |
| groupByKey([numPartitions]) | 对(k,v)类型records按照key进行聚合 |
| reduceByKey(func, [numPartitions]) | 对(k,v)类型records按照key进行合并 |
| aggregateByKey(zeroValue)(seqOp, combOp,[numPartitions]) |  先对数据按照分区聚合，然后按照key值合并    |
| sortByKey([ascending], [numPartitions]) | 对(k,v)类型records按照key进行排序 |
| union(otherDataset) | 直接将两个RDD的分区进行联合 |
| join(otherDataset, [numPartitions]) | (k,v) join(k,w)=>(k,(v,w))|
| cogroup(otherDataset, [numPartitions]) |   （k,v) coGroup(k,w)=>(k,seq(v),seq(w))|
| cartesian(otherDataset) | 笛卡尔积计算 |
| coalesce(numPartitions) | 重新分区 |
| repartition(numPartitions) | 重新分区 |
| repartitionAndSortWithinPartitions(partitioner) | 重新分区，且在分区内进行排序 |


]

---
class:
name:
.left-column[
## RDD Operations
### transformation
]
.right-column[
- transforamtion算子只是提供了一个并行的语义。

- API隐藏了数据划分、并行、通信、容错等复杂的框架代码。

- 算子里面如果有函数参数，该函数为用户自定义的函数(UDF)，该函数为一个串行函数，根据算子的语义对RDD中的数据按照语义的<font color=#A52A2A size=4 >**操作粒度**</font>进行操作。

  1. rdd1.mapValues(s=> s*2)
  2. def func1( i:Int):Int={ i*2}

  rdd1.mapValues (func1)

]
---
class:
name:
.left-column[
## RDD Operations
<!-- ### transformation & action
 -->
 ### transformation
]
.right-column[

#### 操作粒度

- 对整条数据操作

  map, flatMap, filter

- 对(key, value) 中的value操作

  mapValues

- 对整个分区数据操作

  mapPartitions,mapPartitionsWithIndex

- 对分区进行混洗(shuffle)

  reduceBykey,aggregataByKey,gropuByKey,repartition,sortByKey

  repartition,repartitionAndSortWithinPartitions

<!-- - 对多个RDD进行操作

  join, union, coGroup

- 重新分区

  repartition, coalesce  -->



]

---

class:
name:
.left-column[
## RDD Operations
### transformation
### action

]
.right-column[

Action:得到一个结果，或者将RDD存入磁盘。

| Action | Meaning |
| :----------: | :--------------------------------------: |
| countByKey() | 返回每个(k,count(k))，即每个key的个数 |
| reduce(func) | 将所有数据按照func进行聚合 |
|   take(n)    | 返回数据集的前N个数据 |
|  collect()   | 将所有数据提取到driver上，转换成一个数组 |
|   count()    | 获得数据集的数据条数 |
|   first()    | 返回数据集的第一个数据 |
|foreach(func) | 对每个数据进行操作 |
| takeOrdered(n, [ordering])  | 返回排序后数据集的前n个数据 |
| takeSample(withReplacement, num, [seed]) | 根据seed进行抽样，获得num个数据 |
|  saveAsTextFile(path)  | 保存为text文件 |
| saveAsObjectFile(path) | 保存为object文件 |
]

---

class:
name:
.left-column[
## RDD Operations
### transformation
### action
### 合理使用算子
]
.right-column[

- 例子： 一个RDD有10个分区，每个分区有1000条数据。对每条数据进行function操作。

  map算子，调用function 10000次

  mapPartitions算子，调用function10次，但是每次处理一个分区的数据，可能OOM

- 例子：慎重使用collect算子

  collect算子会拉取rdd中所有数据到driver节点，如果数据量过大，会造成driver的OOM，因此collect只适用于拉取小规模(在executor经过处理)的数据

<!-- - repartitionandsortwithinpartitions

  如果需要repartition之后对分区排序，那么使用这个repartitionandsortwithinpar
  titions性能会更好，因为可以将排序放在shuffle过程 -->


- 尽量使用reduceByKey代替groupByKey

  reduceByKey 算子会在map端对数据进行聚合(map-side combine)。
  groupByKey不会在map端进行聚合，会造成在shuffle阶段进行大规模数据传输和在shuffle read端的巨大内存压力。


]




---
class:
name:
.left-column[
## RDD Operations
### transformation
### action
### 合理使用算子
### wordCount Demo
]
.right-column[

```
package sparkApp
import org.apache.spark.{SparkConf, SparkContext}
object SparkWC {

  def main(args: Array[String]){
  val sparkConf = new SparkConf().setAppName(args(0)).setMaster(args(1))
  val sc = new SparkContext(sparkConf)                                  
  sc.textFile(args(2))                                                  
    .flatMap(s => {                                                     
     val parts = s.split(“\\s+")                                       
      parts.map((_,1))                                                  
    })                                                                  
    .reduceByKey(_+_)                                                   
    .saveAsTextFile(args(3)) 
    sc.stop()
    }

  }
```

]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖

]
.right-column[

<figure class="half">
    <img src="../../imgs/rdd_basics/dependencies.png" width="90%" height="50%">
</figure>

]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 

]
.right-column[

<figure class="half">
    <img src="../../imgs/rdd_basics/shuffle.png" width="72%" height="40%">
</figure>

#### Shuffle是瓶颈所在，shuffle的性能优化十分重要。

- 在shuffle write端对map端的分区按照key的hash值进行分块，每个task写入一个partition索引文件（可能存在排序）。

- 磁盘I/O

- 序列化/反序列化

- 网络传输

- 在shuffle read端拉取各个partition索引文件对应分区的数据（可能存在排序)。




]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task

]
.right-column[
#### WordCount Lineage

<figure class="half">
    <img src="../../imgs/rdd_basics/wordcount.png" width="70%" height="35%">
</figure>

- Action触发Job的提交
- 按照Shuffle划分stages
- 每个stage中是独立的n个task，n等于当前stage中rdd分区的数目，每个task分别处理一个分区的数据
- 在一个executor中，并行的task数目和executor的核数有关。



]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[
#### 避免不必要shuffle

- repartition, coalesce, repartitionandsortwithinpartitions 对rdd重新分区

  repartition(numPartitions: Int)=coalesce(numPartitions, shuffle = true)

  如果需要repartition之后对分区排序，那么使用这个repartitionandsortwithinpar
  titions性能会更好，因为可以将分区排序放在shuffle过程

  <figure class="half">
    <img src="../../imgs/rdd_basics/repartition-1.png" width="60%" height="30%">
    &nbsp; &nbsp;  
    <img src="../../imgs/rdd_basics/repartition-2.png" width="30%"  height="30%">
</figure>


]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[
#### map-side Combine

在shuffle write端进行合并数据，可以减少shuffle阶段序列化反序列化开销以及网络传输开销，也会减小在shuffle read端的压力，提升程序性能。

- 尽量使用aggregateByKey和reduceByKey代替groupByKey

| | |
| :---:| :---: |
| groupByKey([numPartitions]) | 没有map-side combine，对(k,v)类型records按照key进行聚合 |
| reduceByKey(func, [numPartitions]) | map-side combine, 对(k,v)类型records按照key进行合并 |
| aggregateByKey(zeroValue)(seqOp, combOp, [numPartitions]) |  先对数据按照分区使用seqOp聚合，然后再按照key值使用combOq合并    |

 一个RDD，变量名为rdd:RDD[(Int,Int)]，对其进行按key，求value之和操作。

 ```
 //reduceByKey with map-side combine
val red=rdd.reduceByKey(_+_)
//aggregateByKey with map-side combine
val agg=rdd.aggregateByKey(0)(((i1,i2)=>i1+i2),((i1,i2)=>(i1+i2)))
//groupByKey without map-side combine
val gbk=rdd.groupByKey().mapValues(iter=> iter.sum)
 ```

]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[
#### 数据倾斜
数据倾斜是由于存在一些<font color=#A52A2A size=4 >**热点数据**</font>，比如某个key存在大量对应的value，或者某个分区存在大量数据(即存在大量hash之后得到同样hash值的key)。

##### 数据倾斜现象
- 绝大多数task很快结束，存在几个straggler.
- 原本能够正常执行的Spark作业，执行某个数据集突然报出OOM（内存溢出）异常。

##### 数据倾斜原理及影响
- shuffle Read需要将各个节点上相同的key拉取到某个节点上的一个task来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。

- 某个task对应数据量大，可能会导致OOM，以及多次重试。

- 每个stage的运行时间由最后一个完成的task决定。
]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[
#### 解决数据倾斜

- 提高shuffle操作的并行度-加大shuffle操作时partition数量

  reduceByKey(func, [numPartitions])

  aggregateByKey(zeroValue)(seqOp, combOp, [numPartitions])  

  优点： 实现简单，可以有效缓解数据倾斜。

  缺点： 针对热点数据比如一个key对应巨量数据的情况无法解决。

- 分阶段聚合

  前面提到的map-side combine

  优点： 对于聚合类的shuffle操作导致的数据倾斜，非常有效。

  缺点： 仅仅适用于聚合类的shuffle操作，适用范围相对较窄。无法处理join类shuffle数据倾斜。

]
---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[
- broadcast实现map join代替 reduce join，<font color=#A52A2A size=4 >**避免shuffle**</font>

  在对RDD使用join类操作(with inputs not co-partitioned)，而且join操作中的一个RDD或表的数据量比较小

  使用broadcast广播小表，然后通过对小表进行遍历完成map join，避免了shuffle的发生

```
val rdd2Data = rdd2.collect()
val rdd2Bc = sc.broadcast(rdd2Data)
def function(tuple: (String,Int)): (String,(Int,String)) ={
    for(value <- rdd2Bc.value){
     if(value._1.equals(tuple._1))
        return (tuple._1,(tuple._2,value._2.toString))
         }
         (tuple._1,(tuple._2,null))
   }
val rdd3 = rdd1.map(function(_))

```



]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[

- Why broadcast?
  
  Spark存在作用域，变量声明在driver上，当task需要操作这些driver上声明的变量时会从driver拷贝副本传输到task。

  broadcast是保证这个由driver声明的变量值只会发送到每个worker上面一份。

  如果不使用broadcast,driver需要给每个task都发送一份副本，如果广播变量较大，会造成大量网络传输。

```
val rdd2Data = rdd2.collect()
//val rdd2Bc = sc.broadcast(rdd2Data)
def function(tuple: (String,Int)): (String,(Int,String)) ={
    for(value <- rdd2Data.value){
     if(value._1.equals(tuple._1))
        return (tuple._1,(tuple._2,value._2.toString))
         }
         (tuple._1,(tuple._2,null))
   }
val rdd3 = rdd1.map(function(_))

```

]

---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[

 - 给key加随机前缀，缓解热点数据

  通过spark提供的takeSample算子可以对RDD进行采样。通过观察看是否存在数据倾斜/热点数据.

  ```
  takeSample(withReplacement, num, [seed])  
 ```

  进行join操作，比如存在热点key “hello",对应大量的value,此时我们给每个key加上(0-10)之间的随机前缀，这些数据就会随机变成(1_hello,v1),(2_hello,v2) ... (10_hello,v10)，这样就缓解了热点的key。




- 混合使用多种调优策略


]

<!-- ---
class:
name:
.left-column[
## RDD 依赖
### 宽依赖 & 窄依赖
### Shuffle 
### Stage & Task
### Shuffle Tuning

]
.right-column[

- Why broadcast?
  
  Spark存在作用域，变量声明在driver上，当executor需要使用driver上的变量，会有driver拷贝一个副本发送到executor。

  broadcast是保证这个由driver声明的变量值只会发送到executor上面一份。

  如果不使用broadcast,每条数据都要调用map里面的function,每调用一次就会由driver拷贝一份副本发送到executor，造成大量网络传输。

] -->


<!-- ---
class: 
name:


.left-column[
## RDD与Task
### 分区与Task

]
.right-column[

- 每个stage里面，有若干个 相互独立的Task。

- Task数目等于被操作RDD的分区数。

- 每个Task分别对RDD的一个分区进行一系列操作。

- 在一个executor中，并行的task数目和executor的核数有关。

] -->



<!-- ---
class: 
name:


.left-column[
## RDD与Task
### 分区与Task

]
.right-column[

- 每个stage里面，有若干个 相互独立的Task。

- Task数目等于被操作RDD的分区数。

- 每个Task分别对RDD的一个分区进行一系列操作。

- 在一个executor中，并行的task数目和executor的核数有关。

] -->


<!-- ---
class: 
name:


.left-column[
## RDD与Task
### 分区与Task
### 内存模型

]
.right-column[
<center class="half">
    <img src="../../imgs/rdd_basics/memory.png" width="30%" height="50%">
</center>

- 当RDD分区里数据量很大时，每个task占用的执行内存比较大，容易造成内存紧张。
- 当executor内存压力大，可以增大分区数量(减少分区数据量)或者减少executor cpu 核数（减小并行处理task的数量)。



] -->


---
class: 
name:


.left-column[
## RDD Persist


]
.right-column[
- 机器学习，图计算等应用存在大量迭代计算。

- 适当的缓存中间数据可以避免重复计算。

  persist(storageLevel)

  cache()=persist(StorageLevel.MEMORY_ONLY)

- 缓存级别

|                     |  |
| :-----------------: | :----:|
|     MEMORY_ONLY     |    只缓存在内存中|
|   MEMORY_AND_DISK   |  缓存在内存和磁盘|
|   MEMORY_ONLY_SER   |  序列化缓存在内存中|
| MEMORY_AND_DISK_SER |   序列化缓存在内存和磁盘|
|      DISK_ONLY      |    只缓存在磁盘|
|    MEMORY_ONLY_2    |    缓存在内存中两份(一份副本)|
|  MEMORY_AND_DISK_2  |  缓存在内核和磁盘两份(一份副本)|
|      OFF_HEAP       |  缓存在堆外 |



]
---
class: 
name:


.left-column[
## 相关链接


]
.right-column[

- RDD论文

  https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf

- RDD算子介绍

  http://spark.apache.org/docs/latest/rdd-programming-guide.html

- spark 配置

  http://spark.apache.org/docs/latest/configuration.html

- 性能调优

  http://spark.apache.org/docs/latest/tuning.html



]
---

class: middle, center, inverse
name: greetings
# Q & A
---
class: center, middle, inverse

# Thanks！

<img style="zoom: 1.0" src="../../imgs/mammut.png"  align="bottom" />

<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        ratio: '16:9',
        slideNumberFormat: 'Slide %current% of %total%',
        // .. or by using a format function
        slideNumberFormat: function (current, total) {
          return ' ' + current + ' of ' + total;
        },
        highlightLanguage: 'scala',
        highlightStyle: 'monokai',
        highlightLines: true,
        // arta, ascetic, dark, default, far, github, googlecode, idea, ir-black, magula, monokai, rainbow, solarized-dark, solarized-light, sunburst, tomorrow, tomorrow-night-blue, tomorrow-night-bright, tomorrow-night, tomorrow-night-eighties, vs, zenburn
        highlightStyle: 'zenburn'
      });
    </script>
  </body>
</html>
